{"cells":[{"cell_type":"code","source":["from pyspark.sql.types import *\nfrom pyspark.sql import Row\nimport ast\nimport json\nimport pandas as pd\nimport numpy as np\nimport requests\nimport pickle\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport os\nfrom pyspark.sql import SQLContext\nsqlContext = SQLContext(sc)\nfrom pyspark.sql import HiveContext\nhiveContext=HiveContext(sc)\nimport sys\nfrom numpy import *\n#%matplotlib inline\ndbutils.fs.mount(\"s3n://%s:%s@%s\" % (ACCESS_KEY, ENCODED_SECRET_KEY, 'data-analysis-sachin'), \"/mnt/%s\" % assignment1)\ndbutils.fs.ls('/mnt/assignment1/csvParquetFiles_new/')"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["#Model Classes\n# %load PieceWise.py\n#Encoder class for spark dataframes\nimport pandas as pd\nfrom numpy import *\nclass encoder:\n    \"\"\"\n    The encoder/decoder class is the base class for all encoder/decoder pairs.\n    Subclasses encode different types of encoding.\n    EncoderLearner is a factory class for fitting encoders to data\n    \"\"\"\n    def __init__(self,raw,max_gap):\n        \"\"\"\n        given a spark DataFrame or Series (raw), find the best model of a given type\n        \"\"\"\n    \n    def compress(self):\n        \"\"\"\n        given a raw sequence and a model, return a compressed representation.\n        \"\"\"\n        self.compressed=None\n        return self.compressed\n    \n    def recon(self,compressed):\n        \"\"\"\n        Recreate the original DataFrame or Series, possibly with errors.\n        \"\"\"\n        Recon=None\n        return Recon\n    \n    def get_size(self):\n        return len(self.compressed)\n    \n    def compute_error(self,S,compressed):\n        if type(compressed)==type(None):\n            compressed=self.compressed\n        #R=self.recon(compressed=compressed,index=S.index)\n        R=self.recon()\n        V=R-S\n        V=V.dropna()\n        return sqrt(sum([v*v for v in V.values]))/len(V)\n      \nclass piecewise_constant(encoder):\n    \"\"\" \n    Represent the signal using a sequence of piecewise constant functions \n    \"\"\"\n    def __init__(self,raw,max_gap):\n      S=raw\n      if type(S) != pd.Series:\n        raise 'encode expects pandas Series as input'\n      self.index=S.index\n      self.Sol=self.fit(S,max_gap)\n    \n    # fit uses dynamic programming to find the best piecewise constant solution\n    # max_gap is the maximal extent of a single step.\n    # Reason for max_gap is that even if the error is small we want to correct\n    # it with some minimal frequence. \n    # Not quite a snapshot because the value will not necessarily change after \n    # max_gap is reached.\n    def fit(self,S,max_gap):\n        S[np.isnan(S)]=0\n        _range=np.max(S)-np.min(S)\n        # _range is a constant that is added to the error at each stop point\n        # Larger values will cause fewer switches.\n        print 'range=',_range\n        #Dynamic programming\n        Sol=[[]]*len(S)  # an array that holds the best partition ending at each point of the sequence.\n                # Each element contains a best current value, a pointer to the last change in best \n                # solution so far and the total error of best solution so far.\n        for i in range(len(S)):\n            if i==0:\n                Sol[i]={'prev':None, 'value':S[0], 'error':0.0, 'switch_no':0}\n            # Sol is indexed by the location in the sequence S\n            # prev: the index of the last switch point\n            # value: current prediction value\n            # error: cumulative error to this point\n            # switch_no: number of switches so far.\n            else:\n                err0 = Sol[i-1]['error']+(Sol[i-1]['value']-S[i])**2\n                best=None\n                best_err=1e20\n                best_val=S[i]\n                for j in xrange(np.max([0,i-max_gap]),i):\n                      _mean=np.mean(S[j:i])\n                      _std=np.std(S[j:i])\n                      err=_std*(i-j)+Sol[j]['error']+_range\n                      if err<best_err:\n                          best=j\n                          best_val=_mean\n                          best_err=err\n                Sol[i]={'prev':best, 'value':best_val, 'error':best_err,\\\n                        'switch_no': Sol[best]['switch_no']+1}\n            #print '\\r',i,Sol[i],\n        return Sol\n    \n    def compress(self,S):\n        Switch_points=[]\n        i=len(self.Sol)-1                # start from the end \n        while i>0:\n            prev=self.Sol[i]['prev']\n            value=self.Sol[i]['value']\n            if self.Sol[prev]['value'] != value:\n                Switch_points.append({'time':S.index[prev],'value':value})\n            i=prev\n        self.compressed=Switch_points\n        return Switch_points\n\n    def recon(self,compressed=None, index=None):\n        #print '\\nindex=',index==None,'\\n'\n        #print '\\ncompressed=',compressed==None,'\\n'\n        if(type(index)==type(None)):\n            index=self.index\n        Recon=pd.Series(index=index)\n        \n        if(type(compressed)==type(None)):\n            compressed=self.compressed\n        for e in compressed:\n            time=e['time']\n            value=e['value']\n            Recon[time]=value\n            \n        return Recon.fillna(method='ffill')\n      \nclass piecewise_linear(encoder):\n    \"\"\" \n    Represent the signal using a sequence of piecewise linear functions \n    \"\"\"\n    def __init__(self,raw,max_gap):\n      S=raw\n      if type(raw) != pd.Series:\n        raise 'encode expects pandas Series as input'\n      self.index=raw.index\n      self.Sol=self.fit(raw,max_gap)\n    \n    # fit uses dynamic programming to find the best piecewise linear solution\n    # max_gap is the maximal extent of a single step.\n    # Reason for max_gap is that even if the error is small we want to correct\n    # it with some minimal frequence. \n    # Not quite a snapshot because the value will not necessarily change after \n    # max_gap is reached.\n    def fit(self,S,max_gap):\n        S[np.isnan(S)]=0\n        _range=np.max(S)-np.min(S)\n        # _range is a constant that is added to the error at each stop point\n        # Larger values will cause fewer switches.\n        print 'range=',_range\n        #Dynamic programming\n        Sol=[[]]*len(S)  # an array that holds the best partition ending at each point of the sequence.\n                # Each element contains a best current value, a pointer to the last change in best \n                # solution so far and the total error of best solution so far.\n        for i in range(len(S)):\n            if i==0:\n                Sol[i]={'prev':None, 'value':S[0], 'error':0.0, 'switch_no':0, 'slope':0}\n            # Sol is indexed by the location in the sequence S\n            # prev: the index of the last switch point\n            # value: current prediction value\n            # error: cumulative error to this point\n            # switch_no: number of switches so far.\n            #slope: slope of th linear line at this point\n            else:\n                err0 = Sol[i-1]['error']+(Sol[i-1]['value']-S[i])**2\n                best=None\n                best_err=1e20\n                best_val=S[i]\n                best_slope=1e20\n                for j in xrange(np.max([0,i-max_gap]),i):\n                    #_mean=np.mean(S[j:i])\n                    _slope=(S[i]-S[j])*1.0/(i-j)\n                    #_std=np.std(S[j:i]\n                    _val=0\n                    _err=0\n                    for k in xrange(j,i):\n                      _val=Sol[j]['value']+_slope*(k-j)\n                      _err+=(Sol[k]['value']-_val)**2\n                    err=_err*1.0/(i-j)+Sol[j]['error']+_range\n                    _val=Sol[j]['value']+_slope*(i-j)\n                    if err<best_err:\n                        best=j\n                        best_val=_val\n                        best_err=err\n                        best_slope=_slope\n                Sol[i]={'prev':best, 'value':best_val, 'error':best_err,\\\n                        'switch_no': Sol[best]['switch_no']+1, 'slope':best_slope}\n            #print '\\r',i,Sol[i],\n        return Sol\n    \n    def compress(self,S):\n        Switch_points=[]\n        i=len(self.Sol)-1                # start from the end \n        while i>0:\n            prev=self.Sol[i]['prev']\n            slope=self.Sol[i]['slope']\n            value=self.Sol[i]['value']\n            if self.Sol[prev]['slope'] != slope:\n                Switch_points.append({'time':S.index[prev],'value':value})\n            i=prev\n        self.compressed=Switch_points\n        return Switch_points\n\n    def recon(self,compressed=None, index=None):\n        #print '\\nindex=',index==None,'\\n'\n        #print '\\ncompressed=',compressed==None,'\\n'\n        print \"HI\"\n        if(type(index)==type(None)):\n            index=self.index\n        Recon=pd.Series(index=index)\n        if(type(compressed)==type(None)):\n            compressed=self.compressed\n        for e in compressed:\n            time=e['time']\n            value=e['value']\n            Recon[time]=value\n        \n        #print Recon    \n        #return Recon.fillna(method='ffill')\n        Recon.interpolate(method=\"linear\", inplace=True)\n        return Recon"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["#All applicable functions\ndef runAnalysisOld(room,template,stTime,enTime,method,tolerance):\n  dataDF=loadf(room,template,stTime,enTime)\n  print len(dataDF)\n  [compressedDF, reconDF]=model(dataDF,method,tolerance)\n  return [dataDF, compressedDF, reconDF]\n  \ndef loadf(room,template,stTime,enTime):\n  query = \"select * from allbuildingsensordata where room='\"+str(room)+\"' and template='\"+str(template)+\"' and timeseries between '\"+ str(stTime) +\"' and '\"+str(enTime)+\"'\"\n  #print query\n  df=hiveContext.sql(query)\n  dataDF=pd.DataFrame(df.select('timeseries','values').collect(),columns=['timeseries','values'])\n  dataDF['timeseries']=dataDF['timeseries'].apply(lambda x:datetime.strptime(x, '%Y-%m-%dT%H:%M:%S+00:00'))\n  dataDF['values']=dataDF['values'].apply(lambda x:float(str(x)))\n  return dataDF\n    \ndef dataPlot(dfArgument,timeLowerBound, timUpperBound):\n  tempDF=dfArgument[dfArgument.timeseries.between(timeLowerBound, timUpperBound)]\n  #if(Rooms!='All'):\n  #  tempDF=tempDF[tempDF['room']==Rooms]\n  #display(tempDF)\n  dataDF=pd.DataFrame(tempDF.select('timeseries','values').limit(5000).collect(),columns=['timeseries','values'])\n  return dataDF\n\ndef model(A,method,tolerance):  \n  pd_df=A\n  sys.stdout.flush()\n  #pd_df=pd.DataFrame(A.select('timeseries','values').limit(5000).collect(),columns=['timeseries','values'])\n  #pd_df.plot(kind='line')\n  S=pd_df['values']\n  _std=np.std(S)\n  print \"Std dev is \",_std\n  if(method=='piecewise_constant'):\n    encoder=piecewise_constant(S,tolerance)\n  elif(method=='piecewise_linear'):\n    encoder=piecewise_linear(S,tolerance)\n  C=encoder.compress(S)\n  R=encoder.recon()\n  print \"type is \",type(R)\n  compressed_df=pd.DataFrame(C)\n  print 'size=',encoder.get_size(),\n  error=encoder.compute_error(S,compressed=C)\n  print 'error=',error, 'error/_std=',error/_std\n  print C\n  return [compressed_df, R]\n  \ndef runAnalysis(table,stTime,enTime,templateCount):\n  templates=['Zone Temperature','Actual Supply Flow','Occupied Clg Min','Occupied Htg Flow','Common Setpoint', 'Actual Heating Setpoint', 'Supply Vel Press', 'Zone Temperature Error',  'Damper Position',  'Warm Cool Adjust', 'Cooling Command', 'HVAC Zone Power', 'Damper Command', 'Cooling Max Flow', 'Occupied Htg Flow','Actual Cooling Setpoint', 'Reheat Valve Command Error']\n  dfs=[]\n  plotTemplates=[]\n  for t in templates[0:templateCount]:\n    try:\n      query = \"select * from \"+str(table)+\" where template='\"+str(t)+\"' and timeseries between '\"+ str(stTime) +\"' and '\"+str(enTime)+\"'\" \n      print query\n      df=hiveContext.sql(query)\n      dataDF=pd.DataFrame(df.select('timeseries','values').collect(),columns=['timeseries','values'])\n      dataDF['timeseries']=dataDF['timeseries'].apply(lambda x:datetime.strptime(x, '%Y-%m-%dT%H:%M:%S+00:00'))\n      dataDF['values']=dataDF['values'].apply(lambda x:float(str(x)))\n      if(t in ['Zone Temperature','Zone Temperature Error']):\n        method='piecewise_linear'\n      else:\n        method='piecewise_constant'\n      [compressedDF, reconDF]=model(dataDF,method,tolerance=96)\n      plotTemplates.append(t)\n      dfs.extend([dataDF,reconDF]) \n    except:\n      print t\n  return [dfs,plotTemplates]\n    \ndef getTime(x,dfTest):\n  return dfTest.at[int(x),'timeseries']\n\ndef plotResults(dfs,plotTemplates):\n  plt.title('compression analysis')\n  #fig = plt.figure(figsize=(15, 8))\n  fig, ax = plt.subplots(figsize=(15, 8))\n  linestyles = ['_', '-', '--', ':']\n  colors = ('b', 'g', 'r', 'c', 'm', 'y', 'k')\n  timeX=dfs[0]['timeseries'].tolist()\n  axes = [ax, ax.twinx()]\n  axes1Count=0\n  axes0Count=0\n  for i in xrange(len(plotTemplates)):\n    try:\n      print 2*i\n      ReconDF=dfs[2*i+1].to_frame(name='values')\n      ReconDF['time']=ReconDF.index\n      ReconDF=ReconDF.dropna()\n      ReconDF=ReconDF.sort(['time'], ascending=[1])\n      ReconDF['timeseries']=ReconDF.apply(lambda x: getTime(x['time'],dfs[2*i]), axis=1)\n      if(plotTemplates[i] in ['Actual Supply Flow','Occupied Command','Damper Position']):\n        axes1Count=1\n        axes[1].plot(dfs[2*i]['timeseries'].tolist(),dfs[2*i]['values'].tolist(),'k--',color=colors[i],label=plotTemplates[i])\n        axes[1].plot(ReconDF['timeseries'].tolist(),ReconDF['values'].tolist(),'k:',color=colors[i],label=plotTemplates[i]+'_reconstructed')\n      else:\n        axes0Count=1\n        axes[0].plot(dfs[2*i]['timeseries'].tolist(),dfs[2*i]['values'].tolist(),'k--',color=colors[i],label=plotTemplates[i])\n        axes[0].plot(ReconDF['timeseries'].tolist(),ReconDF['values'].tolist(),'k:',color=colors[i],label=plotTemplates[i]+'_reconstructed')\n    except:\n      print plotTemplates[i]\n  if(axes1Count==0):\n    print \"axes1Count\",axes1Count\n    print len(timeX)\n    axes[1].plot(timeX,[0 for x in timeX],'k',color='w',label='axes1')\n  if(axes0Count==0):\n    print \"axes0Count\",axes0Count\n    axes[0].plot(timeX,[0 for x in timeX],'k',color='w',label='axes0')\n  axes[0].legend(loc='upper left',fontsize='x-small')\n  axes[1].legend(loc='upper right',fontsize='x-small')\n  axes[1].set_ylabel('scale for top right legend')\n  axes[0].set_ylabel('scale for top left legend')\n  display(fig)\n  \ndef loadTags():\n  tagsDF=sqlContext.read.parquet(\"/mnt/assignment1/csvParquetFiles/tagsDF\")\n  keep=[tagsDF.name,tagsDF.sensor_id,tagsDF.template,tagsDF.timeseries_span]\n  tagsDF=tagsDF.select(*keep)\n  return tagsDF"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["dfs=runAnalysisOld('Rm-2219','Zone Temperature','2014-10-10T23:01:45+00:00','2014-10-24T23:59:18+00:00','piecewise_constant',tolerance=96)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm4226',stTime='2013-12-01',enTime='2013-12-07',templateCount=2)\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm2138',stTime='2013-12-01',enTime='2013-12-07')\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm3214',stTime='2014-02-10',enTime='2014-02-20',templateCount=17)\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm2234',stTime='2014-01-20',enTime='2014-01-30',templateCount=17)\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm3208',stTime='2014-03-20',enTime='2014-03-30',templateCount=17)\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm3214',stTime='2014-02-10',enTime='2014-02-20',templateCount=17)\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm2138',stTime='2014-04-07',enTime='2014-04-14',templateCount=17)\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm2118',stTime='2013-07-01',enTime='2013-07-10',templateCount=17)\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm4226',stTime='2014-03-01',enTime='2014-03-07')\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm2118',stTime='2013-12-01',enTime='2013-12-10',templateCount=17)\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm2118',stTime='2014-06-01',enTime='2014-06-10',templateCount=17)\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm2118',stTime='2014-12-01',enTime='2014-12-10',templateCount=17)\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm2118',stTime='2015-04-01',enTime='2015-04-10',templateCount=17)\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm4226',stTime='2013-07-01',enTime='2013-07-07')\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["[dfs,plotTemplates]=runAnalysis(table='rm2138',stTime='2013-07-01',enTime='2013-07-07')\nprint len(dfs)\nprint plotTemplates\nplotResults(dfs,plotTemplates)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["#get summary table\ndf=hiveContext.sql(\"select * from dataSummary\");\nsummaryDF=pd.DataFrame(df.collect(),columns=['room','template','stTime','enTime'])\nsummaryDF.head()"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["#df=loadf('RF2','Current','2013-07-01','2013-07-14')\ndf['timeseries']=df['timeseries'].apply(lambda x:datetime.strptime(x, '%Y-%m-%dT%H:%M:%S+00:00'))\ndf.head()"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["dfs=runAnalysis('RF2','Current','2013-07-01','2013-07-14','piecewise_constant',tolerance=16)\nplotResults(dfs,'Current')"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["dfs=runAnalysisOld('RM-1125','Actual Heating Setpoint','2015-02-01T00:00:00+00:00','2015-02-14T00:00:00+00:00','piecewise_constant',tolerance=16)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["dfs=runAnalysis('RM-1125','Actual Heating Setpoint','2015-02-01T00:00:00+00:00','2015-02-14T00:00:00+00:00','piecewise_constant',tolerance=16)\nplotResults(dfs,'Actual Heating Setpoint')"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["dfs=runAnalysisOld('Rm-2219','Zone Temperature','2014-10-10T23:01:45+00:00','2014-10-24T23:59:18+00:00','piecewise_constant',tolerance=96)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["dfs=runAnalysis('Rm-2219','Zone Temperature','2014-10-10T23:01:45+00:00','2014-10-24T23:59:18+00:00','piecewise_constant',tolerance=96)\nplotResults(dfs,'Zone Temperature')"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["dfs=runAnalysisOld('Rm-2150','Actual Cooling Setpoint','2015-02-01T00:00:00+00:00','2015-02-14T00:00:00+00:00','piecewise_constant',tolerance=96)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["dfs=runAnalysis('Rm-2150','Actual Cooling Setpoint','2015-02-01T00:00:00+00:00','2015-02-14T00:00:00+00:00','piecewise_constant',tolerance=96)\nplotResults(dfs,'Actual Cooling Setpoint')"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["dfs=runAnalysis('Rm-2109','Warm Cool Adjust','2014-03-01T00:00:00+00:00','2014-03-14T00:00:00+00:00','piecewise_constant',tolerance=96)\nplotResults(dfs,'Warm Cool Adjust')"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["dfs=runAnalysis('RM-1145','Common Setpoint','2014-12-01T00:00:00+00:00','2014-12-14T00:00:00+00:00','piecewise_constant',tolerance=36)\nplotResults(dfs,'Common Setpoint')"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["dfs=runAnalysisOld('RM-B260','Damper Position','2014-12-01T00:00:00+00:00','2014-12-14T00:00:00+00:00','piecewise_constant',tolerance=36)"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["dfs=runAnalysis('RM-B260','Damper Position','2014-12-01T00:00:00+00:00','2014-12-14T00:00:00+00:00','piecewise_constant',tolerance=36)\nplotResults(dfs,'Damper Position')"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"code","source":["dfs=runAnalysisOld('RM-1106','Actual Sup Flow SP','2014-08-01T00:00:00+00:00','2014-08-14T00:00:00+00:00','piecewise_constant',tolerance=96)"],"metadata":{},"outputs":[],"execution_count":33},{"cell_type":"code","source":["dfs=runAnalysis('RM-1106','Actual Sup Flow SP','2014-08-01T00:00:00+00:00','2014-08-14T00:00:00+00:00','piecewise_constant',tolerance=96)\nplotResults(dfs,'Actual Sup Flow SP')"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["dfs=runAnalysisOld('Rm-4127','Actual Supply Flow','2015-02-01T00:00:00+00:00','2015-02-14T00:00:00+00:00','piecewise_constant',tolerance=16)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["dfs=runAnalysis('Rm-4127','Actual Supply Flow','2015-02-01T00:00:00+00:00','2015-02-14T00:00:00+00:00','piecewise_constant',tolerance=16)\nplotResults(dfs,'Actual Supply Flow')"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["dfs=runAnalysis('Rm-3146','Supply Vel Press','2014-02-01T00:00:00+00:00','2014-02-14T00:00:00+00:00','piecewise_constant',tolerance=16)\nplotResults(dfs,'Supply Vel Press')"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["dfs=runAnalysis('Rm-3213','Damper Command','2015-02-01T00:00:00+00:00','2015-02-14T00:00:00+00:00','piecewise_constant',tolerance=96)\nplotResults(dfs,'Damper Command')"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["dfs=runAnalysis('Rm-4127','Actual Supply Flow','2015-02-01T00:00:00+00:00','2015-02-14T00:00:00+00:00','piecewise_constant',tolerance=96)\nplotResults(dfs,'Actual Supply Flow')"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["#dfs=runAnalysis('HW-SYS','2015','2015-03-01 08:00:00','2015-03-08 17:30:00','piecewise_constant')\n#df=loadf('HW-SYS','2015')\n#subDF=dataPlot(df,'2015-03-01 08:00:00','2015-03-08 17:30:00')\n#pd_df=subDF\n#S=pd_df['values']\n#_std=np.std(S)\n#print \"Std dev is \",_std\n\nminErrorGap=10\nminError=1e20\nerrors=[]\nfor maxGap in xrange(10,100):\n  encoder=piecewise_constant(S,maxGap)\n  C=encoder.compress(S)\n  error=encoder.compute_error(S,C)\n  print error\n  errors.append(error)\n  if(error<minError):\n    minError=error\n    minErrorGap=maxGap\nprint minErrorGap\nminError\n#R=encoder.recon()\n#compressed_df=pd.DataFrame(C)\n"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["plt.plot(np.array(errors))\nplt.title('errors vs max_gap')\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"code","source":["sortedErrorIndex=sorted(range(len(errors)), key=lambda k: errors[k])\nprint sortedErrorIndex[0:10]"],"metadata":{},"outputs":[],"execution_count":42},{"cell_type":"code","source":["#Change variables here. general funtion signature is runAnalysis(room,year,startTime,endTime,method) where method can take 3 values-piecewise_constant, piecewise_linear, both. Return object is a list of dataframes in this order-spark dataframe of full data of the room for the given year. pandas dataframe of subset of above data within the given time range. pandas dataframe of the comressed data\ndfs=runAnalysis('HW-SYS','2015','2015-03-01 08:00:00','2015-03-08 17:30:00','piecewise_constant',tolerance=36)\nplotResults(dfs)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"code","source":["dfs=runAnalysis('HW-SYS','2015','2015-03-01 08:00:00','2015-03-08 17:30:00','piecewise_constant',tolerance=9)\nplotResults(dfs)"],"metadata":{},"outputs":[],"execution_count":44},{"cell_type":"code","source":["dfs=runAnalysis('HW-SYS','2015','2015-03-01 08:00:00','2015-03-08 17:30:00','piecewise_linear',tolerance=9)\nplotResults(dfs)"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["#Plots for other rooms, times and methods are below"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["dfs=runAnalysis('Rm-4126','2014','2014-12-01 08:00:00','2014-12-08 17:30:00','piecewise_constant',tolerance=96)\nplotResults(dfs)"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["dfs=runAnalysis('Rm-2154','2014','2014-12-01 08:00:00','2014-12-08 17:30:00','piecewise_constant',tolerance=40)\nplotResults(dfs)"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"code","source":["dfs=runAnalysis('RM-1208B','2015','2015-03-01 08:00:00','2015-03-08 17:30:00','piecewise_constant',tolerance=96)\nplotResults(dfs)"],"metadata":{},"outputs":[],"execution_count":49},{"cell_type":"code","source":["dfs=runAnalysis('Rm-3152','2015','2015-03-01 08:00:00','2015-03-08 17:30:00','piecewise_constant',tolerance=96)\nplotResults(dfs)"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"code","source":["dfs=runAnalysis('Rm-4130','2015','2015-03-01 08:00:00','2015-03-08 17:30:00','piecewise_constant',tolerance=96)\nplotResults(dfs)"],"metadata":{},"outputs":[],"execution_count":51},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":52}],"metadata":{"name":"BSA-results","notebookId":33302},"nbformat":4,"nbformat_minor":0}
